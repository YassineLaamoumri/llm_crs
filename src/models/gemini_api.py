import os
import re
from google import genai
from google.genai import types
from fastapi_app.config import GEMINI_API_KEY  # Import the API key from config


class GeminiClient:
    def __init__(
        self,
        api_key: str = None,
        model_audio: str = "gemini-2.0-flash-thinking-exp-01-21",
        model_rag: str = "gemini-2.0-flash-thinking-exp-01-21",  # Replace with your default RAG model name if different
    ):
        """
        Initialize the GeminiClient with separate models for audio processing and RAG.
        If no API key is provided, it will be read from the GEMINI_API_KEY environment variable.
        """
        self.api_key = api_key or GEMINI_API_KEY
        if not self.api_key:
            raise ValueError(
                "Gemini API key must be provided or set in the GEMINI_API_KEY environment variable."
            )
        self.client = genai.Client(api_key=self.api_key)
        self.model_audio = model_audio
        self.model_rag = model_rag

    def generate_audio_processing(
        self, audio_file_path: str, insert_input: str = ""
    ) -> str:
        """
        Process an audio file for transcription and JSON generation.

        This method uploads an audio file, provides detailed instructions to the Gemini model,
        and returns the generated output based on the transcript instructions.
        The Call ID is dynamically extracted from the first number in the audio filename.

        Parameters:
            audio_file_path (str): Path to the audio file to process.
            insert_input (str): Text to replace the "INSERT_INPUT_HERE" placeholder.

        Returns:
            str: The output generated by the Gemini model.
        """
        # Extract the Call ID from the audio file name (first number in the filename)
        filename = os.path.basename(audio_file_path)
        match = re.search(r"(\d+)", filename)
        call_id = match.group(1) if match else "Unknown"

        # Upload the audio file
        files = [self.client.files.upload(file=audio_file_path)]

        # Build the conversation contents for audio processing with dynamic Call ID
        json_prompt = f"""
{{
  "arabic": {{
    "cleaned_conversation": "<Your cleaned and labeled Arabic conversation here>",
    "knowledge_base_entry": {{
      "Call ID": "{call_id}",
      "Issue Summary": "<Concise summary of the customer's problem in Arabic>",
      "Customer's Request": "<Detailed customer inquiry in Arabic>",
      "Agent's Response": "<Summary of agent's actions in Arabic>",
      "Outcome": "<Confirmation or Rejection in Arabic>",
      "Outcome Reason": "<Brief explanation of the outcome in Arabic>",
      "Upsell Information": "<Optional: details on any upsell attempt and result, or 'Not Applicable'>",
      "Additional Metadata": {{
        "Call Duration": "<Call duration if available, if not Unknown>",
        "Overall Sentiment": "<Sentiment analysis in Arabic>",
        "Keywords": "<List of significant keywords in Arabic>",
        "Contextual Factors": "<External influencing factors in Arabic>",
        "Correlation Patterns": "<Patterns observed with confirmation rates in Arabic>"
      }},
      "Agent Guidance": {{
        "Actions to Do": "<Recommended actions for the agent in Arabic>",
        "Actions to Avoid": "<Actions that should be avoided by the agent in Arabic>"
      }}
    }}
  }},
  "english": {{
    "cleaned_conversation": "<English translation of the conversation>",
    "knowledge_base_entry": {{
      "Call ID": "{call_id}",
      "Issue Summary": "<Concise summary of the customer's problem in English>",
      "Customer's Request": "<Detailed customer inquiry in English>",
      "Agent's Response": "<Summary of agent's actions in English>",
      "Outcome": "<Confirmation or Rejection in English>",
      "Outcome Reason": "<Brief explanation of the outcome in English>",
      "Upsell Information": "<Optional: details on any upsell attempt and result, or 'Not Applicable'>",
      "Additional Metadata": {{
        "Call Duration": "<Call duration if available, if not Unknown>",
        "Overall Sentiment": "<Sentiment analysis in English>",
        "Keywords": "<List of significant keywords in English>",
        "Contextual Factors": "<External influencing factors in English>",
        "Correlation Patterns": "<Patterns observed with confirmation rates in English>"
      }},
      "Agent Guidance": {{
        "Actions to Do": "<Recommended actions for the agent in English>",
        "Actions to Avoid": "<Actions that should be avoided by the agent in English>"
      }}
    }}
  }}
}}
"""

        contents = [
            types.Content(
                role="user",
                parts=[
                    types.Part.from_uri(
                        file_uri=files[0].uri,
                        mime_type=files[0].mime_type,
                    ),
                ],
            ),
            types.Content(
                role="model",
                parts=[
                    types.Part.from_text(
                        text=(
                            "The user wants me to process an Arabic e-commerce call transcript and output a JSON object containing:\n"
                            "1. A cleaned, speaker-labeled Arabic conversation.\n"
                            "2. A structured knowledge base entry in Arabic with specific variables (Call ID, Issue Summary, etc.).\n"
                            "3. A complete English translation of both the conversation and the knowledge base entry.\n\n"
                            "Please follow the detailed instructions provided."
                        )
                    ),
                    types.Part.from_text(text=json_prompt),
                ],
            ),
            types.Content(
                role="user",
                parts=[
                    types.Part.from_text(text=insert_input),
                ],
            ),
        ]

        # Configure generation parameters for audio processing
        generate_content_config = types.GenerateContentConfig(
            temperature=0.7,
            top_p=0.9,
            top_k=64,
            max_output_tokens=65536,
            response_mime_type="text/plain",
            system_instruction=[
                types.Part.from_text(
                    text=(
                        "You are provided with a raw transcript from an audio file of an e-commerce service call. "
                        "The conversation is in Arabic and includes various dialects. Your task is to process this input, "
                        "clean and structure the conversation, extract actionable insights, and output a final JSON object "
                        "according to the provided instructions."
                    )
                ),
            ],
        )

        # Generate content using the audio processing model
        output = ""
        for chunk in self.client.models.generate_content_stream(
            model=self.model_audio,
            contents=contents,
            config=generate_content_config,
        ):
            output += chunk.text
        return output

    def generate_rag(self, input_text: str) -> str:
        """
        Generate output using retrieval augmented generation (RAG) based on the provided input text.

        Parameters:
            input_text (str): The input text for the RAG process.

        Returns:
            str: The output generated by the Gemini model.
        """
        contents = [
            types.Content(
                role="user",
                parts=[
                    types.Part.from_text(text=input_text),
                ],
            ),
        ]

        # Configure generation parameters for RAG
        generate_content_config = types.GenerateContentConfig(
            temperature=0.7,
            top_p=0.9,
            top_k=64,
            max_output_tokens=1024,
            response_mime_type="text/plain",
            system_instruction=[
                types.Part.from_text(
                    text=(
                        "You are an AI assistant specialized in retrieval augmented generation. "
                        "Process the input text and provide a concise, informative answer."
                    )
                ),
            ],
        )

        output = ""
        for chunk in self.client.models.generate_content_stream(
            model=self.model_rag,
            contents=contents,
            config=generate_content_config,
        ):
            output += chunk.text
        return output


if __name__ == "__main__":
    # Example usage:
    gemini_client = GeminiClient()

    # Example for audio processing:
    audio_result = gemini_client.generate_audio_processing(
        "1234_Rejected(Fake_AD)_2.wav", "INSERT_INPUT_HERE"
    )
    print("Audio Processing Output:")
    print(audio_result)
