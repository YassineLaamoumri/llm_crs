import os
from google import genai
from google.genai import types
from fastapi_app.config import GEMINI_API_KEY  # Import the API key from config


class GeminiClient:
    def __init__(
        self,
        api_key: str = None,
        model_audio: str = "gemini-2.0-flash-thinking-exp-01-21",
        model_rag: str = "gemini-2.0-flash-thinking-exp-01-21",  # Replace with your default RAG model name
    ):
        """
        Initialize the GeminiClient with separate models for audio processing and RAG.
        If no API key is provided, it will be read from the GEMINI_API_KEY environment variable.
        """
        self.api_key = api_key or GEMINI_API_KEY
        if not self.api_key:
            raise ValueError(
                "Gemini API key must be provided or set in the GEMINI_API_KEY environment variable."
            )
        self.client = genai.Client(api_key=self.api_key)
        self.model_audio = model_audio
        self.model_rag = model_rag

    def generate_audio_processing(
        self, audio_file_path: str, insert_input: str = ""
    ) -> str:
        """
        Process an audio file for transcription and JSON generation.

        This method uploads an audio file, provides detailed instructions to the Gemini model,
        and returns the generated output based on the transcript instructions.

        Parameters:
            audio_file_path (str): Path to the audio file to process.
            insert_input (str): Text to replace the "INSERT_INPUT_HERE" placeholder.

        Returns:
            str: The output generated by the Gemini model.
        """
        # Upload the audio file
        files = [self.client.files.upload(file=audio_file_path)]

        # Build the conversation contents for audio processing
        contents = [
            types.Content(
                role="user",
                parts=[
                    types.Part.from_uri(
                        file_uri=files[0].uri,
                        mime_type=files[0].mime_type,
                    ),
                ],
            ),
            types.Content(
                role="model",
                parts=[
                    types.Part.from_text(
                        text=(
                            "The user wants me to process an Arabic e-commerce call transcript and output a JSON object containing:\n"
                            "1. **Cleaned Arabic Conversation:** Standard Arabic, speaker-labeled, slang removed.\n"
                            "2. **Knowledge Base Entry:** Structured summary in Arabic with specific variables (Call ID, Issue Summary, etc.).\n"
                            "3. **English Translation:** Translation of both the cleaned Arabic conversation and the knowledge base entry.\n\n"
                            "Please follow the detailed instructions provided."
                        )
                    ),
                    types.Part.from_text(
                        text="""```json
{
  "cleaned_arabic_conversation": "<Your cleaned and labeled Arabic conversation here>",
  "knowledge_base_entry": {
      "Call ID": "<Unique identifier>",
      "Issue Summary": "<Concise summary of the customer's problem>",
      "Customer's Request": "<Detailed customer inquiry>",
      "Agent's Response": "<Summary of agent's actions>",
      "Outcome": "<Confirmation or Rejection>",
      "Outcome Reason": "<Brief explanation of the outcome>",
      "Upsell Information": "<Details on upsell attempt and result>",
      "Additional Metadata": {
         "Call Duration": "<Call duration if available>",
         "Overall Sentiment": "<Sentiment analysis>",
         "Keywords": "<List of significant keywords>",
         "Contextual Factors": "<Any external influencing factors>",
         "Correlation Patterns": "<Patterns observed with confirmation rates>"
      },
      "Agent Guidance": {
         "Actions to Do": "<Recommended actions for the agent>",
         "Actions to Avoid": "<Actions that should be avoided>"
      }
  },
  "english_translation": {
    "Cleaned Conversation": "<English translation of the conversation>",
    "Knowledge Base Entry": {
       "Call ID": "<Unique identifier>",
       "Issue Summary": "<English summary>",
       "Customer's Request": "<English customer details>",
       "Agent's Response": "<English summary of agent's actions>",
       "Outcome": "<English outcome>",
       "Outcome Reason": "<English explanation>",
       "Actions to Do": "<English recommended actions>",
       "Actions to Avoid": "<English actions to avoid>",
       "Upsell Information": "<English upsell details>",
       "Additional Metadata": "<English additional insights>"
    }
  }
}
```"""
                    ),
                ],
            ),
            types.Content(
                role="user",
                parts=[
                    types.Part.from_text(text=insert_input),
                ],
            ),
        ]

        # Configure generation parameters for audio processing
        generate_content_config = types.GenerateContentConfig(
            temperature=0.7,
            top_p=0.9,
            top_k=64,
            max_output_tokens=65536,
            response_mime_type="text/plain",
            system_instruction=[
                types.Part.from_text(
                    text=(
                        "You are provided with a raw transcript from an audio file of an e-commerce service call. "
                        "The conversation is in Arabic and includes various dialects. Your task is to process this input, "
                        "clean and structure the conversation, extract actionable insights, and output a final JSON object "
                        "according to the provided instructions."
                    )
                ),
            ],
        )

        # Generate content using the audio processing model
        output = ""
        for chunk in self.client.models.generate_content_stream(
            model=self.model_audio,
            contents=contents,
            config=generate_content_config,
        ):
            output += chunk.text
        return output

    def generate_rag(self, input_text: str) -> str:
        """
        Generate output using retrieval augmented generation (RAG) based on the provided input text.

        Parameters:
            input_text (str): The input text for the RAG process.

        Returns:
            str: The output generated by the Gemini model.
        """
        contents = [
            types.Content(
                role="user",
                parts=[
                    types.Part.from_text(text=input_text),
                ],
            ),
        ]

        # Configure generation parameters for RAG
        generate_content_config = types.GenerateContentConfig(
            temperature=0.7,
            top_p=0.9,
            top_k=64,
            max_output_tokens=1024,
            response_mime_type="text/plain",
            system_instruction=[
                types.Part.from_text(
                    text=(
                        "You are an AI assistant specialized in retrieval augmented generation. "
                        "Process the input text and provide a concise, informative answer."
                    )
                ),
            ],
        )

        output = ""
        for chunk in self.client.models.generate_content_stream(
            model=self.model_rag,
            contents=contents,
            config=generate_content_config,
        ):
            output += chunk.text
        return output


if __name__ == "__main__":
    # Example usage:
    gemini_client = GeminiClient()

    # Example for audio processing:
    audio_result = gemini_client.generate_audio_processing(
        "Rejected(Fake_AD)_2.wav", "INSERT_INPUT_HERE"
    )
    print("Audio Processing Output:")
    print(audio_result)

    # Example for RAG:
    rag_result = gemini_client.generate_rag("Your RAG input text here")
    print("\nRAG Output:")
    print(rag_result)
